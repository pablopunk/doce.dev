name: Opencode Supervisor

on:
  schedule:
    - cron: "0 4 * * *"
  workflow_dispatch:

env:
  LOOKBACK_HOURS: 24

jobs:
  opencode-supervisor:
    runs-on: self-hosted
    permissions:
      contents: write
      pull-requests: write
      id-token: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Get recent commits
        id: commits
        run: |
          COMMITS=$(git log --since="${{ env.LOOKBACK_HOURS }} hours ago" --pretty=format:"- %h %s" 2>/dev/null || echo "")
          if [ -z "$COMMITS" ]; then
            echo "No commits in the last ${{ env.LOOKBACK_HOURS }} hours"
            echo "has_commits=false" >> $GITHUB_OUTPUT
          else
            echo "has_commits=true" >> $GITHUB_OUTPUT
            {
              echo "list<<EOF"
              echo "$COMMITS"
              echo "EOF"
            } >> $GITHUB_OUTPUT
          fi

      - name: Run opencode
        if: steps.commits.outputs.has_commits == 'true'
        uses: sst/opencode/github@latest
        env:
          OPENCODE_API_KEY: ${{ secrets.OPENCODE_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          model: opencode/kimi-k2.5
          prompt: |
            Read and understand @AGENTS.md to learn the project's rules and conventions.
            Then analyze this codebase for any improvements that adhere to those rules.

            **IMPORTANT**: Bundle all improvements into a SINGLE pull request. Do not create separate PRs for different domains.

            If you find improvements that align with AGENTS.md and you're confident, create one comprehensive PR with all the changes.
            If you're not confident or it requires opinionated input, create an issue instead.
            If no improvements are found, exit silently without creating a PR or issue.
            If there's an existing issue or PR tackling that same concern, do not do anything.
