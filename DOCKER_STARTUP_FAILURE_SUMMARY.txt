================================================================================
DOCKER CONTAINER STARTUP FAILURE - ROOT CAUSE ANALYSIS
================================================================================

PROJECT: hello-world-page (92a37799eec041bd7e2966b4)
ERROR MESSAGE: "Setup timeout: starting_docker exceeded 120000ms"
ACTUAL STATUS: Docker containers are HEALTHY and RUNNING

================================================================================
KEY FINDINGS
================================================================================

1. DOCKER CONTAINERS ARE ACTUALLY RUNNING SUCCESSFULLY
   ✓ Preview service (port 62770) - UP, healthy, responding to requests
   ✓ OpenCode service (port 62771) - UP, healthy, responding to requests
   ✓ Both services have been running for 4+ minutes
   ✓ Docker compose logs show successful initialization

2. QUEUE JOB IS STUCK IN ZOMBIE STATE
   Job: docker.waitReady
   State: queued
   Attempts: 3
   Max Attempts: 3
   Problem: attempts < max_attempts = 3 < 3 = FALSE (can never be claimed again)

3. TWO INDEPENDENT TIMEOUT SYSTEMS CREATED FAILURE
   System A: Queue timeout (120s from docker.composeUp end)
   System B: Presence timeout (120s from PROJECT CREATION)
   
   Project created: 2025-12-19 23:59:16
   When presence checked: 2025-12-20 01:04 (64+ minutes later)
   Result: System B fired, marked setup as failed

================================================================================
ROOT CAUSES (In Order of Impact)
================================================================================

CRITICAL #1: Queue Job Polling Miscounts Attempts
   Location: src/server/queue/handlers/dockerWaitReady.ts + queue.worker.ts
   Problem: Each time docker.waitReady polls (reschedules), it increments attempts
   Lifecycle:
   - Attempt 1: claim job, poll, reschedule (attempts: 0→1)
   - Attempt 2: claim job, poll, reschedule (attempts: 1→2)
   - Attempt 3: claim job, poll, reschedule (attempts: 2→3)
   - Attempt 4: FAIL - attempts < max_attempts = 3 < 3 is FALSE
   Result: Job permanently stuck in queued state

CRITICAL #2: Claim Condition Doesn't Account for Polling
   Location: src/server/queue/queue.model.ts line 417
   SQL: WHERE ... AND attempts < max_attempts
   Issue: No distinction between "retry on error" and "reschedule for polling"
   Fix: Polling jobs should track reschedule_count separately from attempts

HIGH #3: Presence Timeout Uses Wrong Time Reference
   Location: src/server/presence/manager.ts line 132
   Code: const elapsed = Date.now() - project.createdAt.getTime()
   Issue: Measures from project creation, not from phase start
   Example:
   - Project created at 23:59:16
   - Docker started at 23:59:20 (4 seconds later)
   - Timeout is 120 seconds (2 minutes)
   - At 01:04 (65 minutes total), timeout fires
   - But docker phase only took 2 minutes!
   Fix: Track setup_started_at time, use that instead

MEDIUM #4: Race Between Queue Worker and Presence Check
   Problem: Presence heartbeat checks every 15 seconds
   - If user opens project during critical window
   - And queue worker hasn't claimed job yet
   - Presence timeout fires
   - Job is marked failed before being processed

================================================================================
SYMPTOM TIMELINE
================================================================================

23:59:16 - Project created (setup_phase: not_started)
23:59:20 - docker.composeUp job completed successfully
23:59:22 - docker.waitReady job enqueued (setup_phase: starting_docker)
23:59:22+ - docker.waitReady polls every second, reschedulating itself
00:00:22 - After 60 seconds, attempts already at max (3 reschedules)
00:01:22 - Job is stuck, can't be claimed anymore
01:04:00 - Presence heartbeat fires (65 minutes after creation)
01:04:00 - Presence calculates elapsed = 65 minutes > 120 seconds timeout
01:04:00 - Setup marked as FAILED (even though containers are healthy)

================================================================================
WHY THIS IS CRITICAL
================================================================================

1. User sees "Setup failed" but containers are actually running
2. No way for user to recover - UI blocks access to healthy project
3. Orphaned database state - job will never process
4. Timing-dependent - works on fast systems, fails under load
5. Silent failure - containers keep running but UI shows error

================================================================================
AFFECTED PROJECTS
================================================================================

Verified affected:
- 92a37799eec041bd7e2966b4 (hello-world-page)
- 263aa42c597eb0f56d4970e7 (dark-notes)

Likely affects: ALL new projects in the system

================================================================================
REQUIRED FIXES (Priority Order)
================================================================================

1. IMMEDIATE: Fix queue job polling to not increment attempts on reschedule
   - Option A: Add reschedule_count field separate from attempts
   - Option B: Don't count reschedules as attempts (disallow reschedule on error)
   - Affects: queue.worker.ts, queue.model.ts, dockerWaitReady.ts

2. URGENT: Fix presence timeout to use phase start time, not project creation
   - Add setup_started_at field to projects table
   - Update presence manager to use correct time reference
   - Set setup_started_at when phase transitions to starting_docker
   - Affects: projects.schema.ts, presence/manager.ts, queue handlers

3. HIGH: Prevent orphaned jobs by handling max_attempts gracefully
   - When job reaches max_attempts during reschedule, fail with specific error
   - Or: Implement unlimited reschedules for wait/poll operations

4. MEDIUM: Add observability
   - Log queue claim attempts and reasons for failures
   - Track how many times jobs reschedule vs fail with errors
   - Alert on jobs stuck in zombie state

================================================================================
VERIFICATION
================================================================================

Containers are healthy:
- docker compose ps shows both UP and healthy
- Health checks passing
- HTTP endpoints responding correctly
- No errors in container logs
- Astro dev server serving content
- OpenCode API fully operational

================================================================================
ATTACHED DOCUMENT
================================================================================

Full technical analysis saved to: DOCKER_STARTUP_FAILURE_ANALYSIS.md
Contains:
- Detailed timeline with exact timestamps
- Database queries and results
- Code snippets showing exact bugs
- Architecture analysis
- Reproduction steps
